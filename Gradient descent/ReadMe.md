# Gradient descent<br>

Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient of the function at the current point<br>

# Problem Statement<br>

Find w that minimizes the loss
